<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Have a nice day, cheio</title>
    <link>https://cheioKID.github.io/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on Have a nice day, cheio</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 25 Jan 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://cheioKID.github.io/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>PCA Trail</title>
      <link>https://cheioKID.github.io/post/machine-learning/pca-trail/</link>
      <pubDate>Fri, 25 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://cheioKID.github.io/post/machine-learning/pca-trail/</guid>
      <description>Note Prelude 方差~离散程度~可区分度
不同投影的损失
successive orthogonal components 连续正交分量，在fit方法中学习n个分量
奇异值分解SVD
PCA假定以原点为中心，所以数据需要先中心化(standard scale)
from sklearn.preprocessing import StandardScaler X=StandardScaler().fit(X).transform(X) # 一般中心化标准化后pca才能体现出效果  Conclusion 经过分析速度得到成倍的提升
PCA 的效果会比 LDA 好一些，还没弄清楚原因
Error Detail ValueError: n_components=25 must be between 1 and min(n_samples, n_features)=24 with svd_solver=&#39;randomized&#39;  n_components只能取shape的较小值，是因为SVD吗，现在还不清楚
这种情况下只能提升样本量
Source Code # -*- coding:utf-8 -*- from sklearn.svm import SVC from skimage import img_as_ubyte from sklearn.utils import Bunch import numpy as np from PIL import Image import matplotlib.pyplot as plt from sklearn.</description>
    </item>
    
    <item>
      <title>Know Face Recognition Sample</title>
      <link>https://cheioKID.github.io/post/machine-learning/know-face-recognition-sample/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://cheioKID.github.io/post/machine-learning/know-face-recognition-sample/</guid>
      <description>Interpretation  dataset.images : numpy array of shape (13233, 62, 47) Each row is a face image corresponding to one of the 5749 people in the dataset. Changing the slice_ or resize parameters will change the shape of the output.
 n_samples, h, w = lfw_people.images.shape # no. of samples, height of image and width of image   dataset.data : numpy array of shape (13233, 2914) Each row corresponds to a ravelled face image of original size 62 x 47 pixels.</description>
    </item>
    
    <item>
      <title>Know LSTM</title>
      <link>https://cheioKID.github.io/post/machine-learning/to-know-lstm/</link>
      <pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://cheioKID.github.io/post/machine-learning/to-know-lstm/</guid>
      <description>生成句子CNN
预测单词LSTM
背景知识 RNN 循环神经网络的隐藏层中，输出不仅取决于当前的输入还取决于上一时间隐藏层的输出结果。
可以看到RNN包含历史信息（A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor.）

RNN可以将历史信息关联到当前的任务中，比如根据视频的历史帧赋予对当前帧的理解（One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames might inform the understanding of the present frame.）

如果相关信息和所需位置的差距很小，RNN就可以学习使用过去的信息（In such cases, where the gap between the relevant information and the place that it’s needed is small, RNNs can learn to use the past information.</description>
    </item>
    
  </channel>
</rss>